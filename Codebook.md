# Wearable Computing
## Creating a Tidy Dataset from Publically Available Data on Samsung Galaxy S Smartphones
====================================

![alt text](http://archive.ics.uci.edu/ml/assets/logo.gif)  
Source: archive.ics.uci.edu/ml/assets/logo.gif  

**References:**  
[1] Reyes-Ortiz, J.L., Anguita, D., Ghio, A., & Oneto, L. (2012, December). *Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine.* Retreived from http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones.  
[2] Coursera Data Source. Retrieved from https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip.  
 
### CONTENTS 

**1) Variable Dictionary**  
**2) Data Files Required to Reproduce Analysis**    
**3) Data Transformations in script run_analysis.R**  
====  

#### Variable Dictionary  

All data is based on work by Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto [1] and furthered refined by course instructors [2].  

A total of 81 variables appears in the synthesized tidy dataset. The first two are identifier variables:  
* subjectid - categorical variable identifying the subject by identification number {1 through 30}  
* activities - categorical variable identifying one of six activities taken by the subject {walking, walkingupstairs, walkingdownstairs, sitting, standing, laying}. It is the dependent variable.  

The remaining 79 variables are all numerical and serve as the explanatory (independent) variables. The 79 variables are comprised of two categories of signals: time domain and frequency domain:  

**Time domain signals (variables) - as denoted by the "t" prefix**  
| H1 | h2 |
|------------------------------------|------------------------------------|
| ASDF | ASDF |



Two basic classes of variables were constructed from 

The set of variables that were estimated from these signals are: 

mean(): Mean value
std(): Standard deviation


  

* tBodyAcc-XYZ
* tGravityAcc-XYZ
* tBodyAccJerk-XYZ
* tBodyGyro-XYZ
* tBodyGyroJerk-XYZ
* tBodyAccMag
* tGravityAccMag
* tBodyAccJerkMag
* tBodyGyroMag
* tBodyGyroJerkMag  

* fBodyAcc-XYZ
* fBodyAccJerk-XYZ
* fBodyGyro-XYZ
* fBodyAccMag
* fBodyAccJerkMag
* fBodyGyroMag
* fBodyGyroJerkMag

These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 

Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). 

These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.


#### Original files in the dataset
The merged dataset consisted of eight files:

Dependent Variables:

* y_train.txt - containing activity performed for each observation in the training dataset
* y_test.txt - containing activity performed for each observation in the test dataset

Explanatory Variables:

* X_train.txt - containing the training set of explanatory variable data
* X_test.txt - containing the test set of explanatory variable data

Subject Variables:

* subject_train.txt - containing subjects extracted for the train set
* subject_test.txt - containing subjects used in the test set

Variable Names:

* features.txt - containing names of all the explanatory variables
* activity_labels.txt - containing names of the six dependent variables

###Transformations
1) After reading in all the tables explained above, the train and test datasets were merged into three dataframes using the rbind() command:

* activities - contains the y-train.txt and y-test.txt data
* subjects - contains the subject_train.txt and subject_test.txt data
* data - contains the explanatory variables from X_train.txt and X-test.txt

2) A new variable (activity) was generated by transforming the activities codes into plain names from the file "activity_labels.txt". Additionally, that variable was also transformed into a factor variable.

3) The measures for mean() and std() for each of the measures were extracted from the dataset named data, resulting in a dataset called dataInt 

4) A single data frame called transDatawas created by using the cbind() command to connect the three tables and one new variable in this order:

* [,1] subject {from subjects}
* [,2] activityID {from activities}
* [,3] activity {new variable with plain name of ActivityID}
* [,4:82] by variable features {from dataInt}

5) The tidy data set reduces the number of rows from 10,299 to 180. It provides the data grouped first by subject and then activity. 180 rows meets the tidy data rules because each row is an independent observation of means and standard deviations and each column is a separate variable. This data can then be manipulated by users to summarize means and standard deviations rolled up by subject or by activity.


For purposes of this data analysis, seven variables including the word "Mean" were not included in the tidy dataset as they were not means() of primary variables. Those variables ignored include:

* angle(tBodyAccMean,gravity)
* angle(tBodyAccJerkMean),gravityMean)
* angle(tBodyGyroMean,gravityMean)
* angle(tBodyGyroJerkMean,gravityMean)
* angle(X,gravityMean)
* angle(Y,gravityMean)
* angle(Z,gravityMean)


##Variable Dictionary














Title
========================================================

This is an R Markdown document. Markdown is a simple formatting syntax for authoring web pages (click the **Help** toolbar button for more details on using R Markdown).

When you click the **Knit HTML** button a web page will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
summary(cars)
```

You can also embed plots, for example:

```{r fig.width=7, fig.height=6}
plot(cars)
```

